#!/usr/bin/perl -w
#
# $Id$
#
use strict;
use lib qw();	# Required for _perl_libpaths RPM option
use DBI;
use Digest::SHA1 qw/ sha1_hex /;
use Getopt::Long qw/ :config gnu_getopt ignore_case /;
use File::Basename;

# This file contains the SQL statements needed
# to set up a 'slurm_job_log' table in a 'slurm' DB
# on a MySQL server.
#
# It can also be used to backfill the database by
# inserting records from a list of slurm job completion
# logfiles.
#
# Adam Moody <moody20@llnl.gov>

# Required for _path_env_var RPM option
$ENV{PATH} = '/bin:/usr/bin:/usr/sbin';

my %conf = ();

##############################
#  Usage:
#############################
my $progname = basename $0;

$conf{usage} = <<EOF
Usage: $progname [OPTIONS]... [FILES]...

Create SLURM job completion log database along with user accounts to
access it, and/or backfill the database from SLURM job completion
logfiles.

    -h, --help        Display this message.
    -v, --verbose     Be verbose.
    -d, --drop        Drop existing table.
    -c, --create      Create slurm database, slurm & slurm_read users, and table.
    -x, --convert     Convert slurm_job_log table to version 2 (add procs and extend nodelist columns).
    -i, --info        Print information about current DB.
    -b, --backfill    Backfill database from SLURM joblog files in ARGV.
    -L, --localhost   Connect to DB over localhost instead of configured SQL host.

EOF
;

sub usage { print STDERR $conf{usage}; exit 0; }

##############################
#  Parse Command-line
#############################
# set defaults and read in command-line options
$conf{backfill} = "";
$conf{create}   = 0;
$conf{convert}  = 0;
$conf{drop}     = 0;
$conf{localhost}= 0;
$conf{verbose}  = 0;
$conf{info}     = 0;

GetOptions (
   "help|h"         => \$conf{help},
   "backfill|b"     => \$conf{backfill},
   "create|c"       => \$conf{create},
   "convert|x"      => \$conf{convert},
   "drop|d"         => \$conf{drop},
   "localhost|L"    => \$conf{localhost},
   "info|i"         => \$conf{info},
   "verbose|v+"     => \$conf{verbose},
) or usage ();

if (!$conf{create} !$conf{convert} && !$conf{drop} && !$conf{backfill} && !$conf{info}) {
    log_error ("Specify at least one of --{create,convert,drop,backfill,info}\n");
    usage ();
}

if ($conf{help}) {
    usage ();
}

#############################
#  Read Config File.
#############################

# Config Defaults
$conf{confdir}     = "/etc/slurm";
$conf{db}          = "slurm";
$conf{sqlhost}     = "sqlhost";
$conf{ro}{sqluser} = "slurm_read";
$conf{ro}{sqlpass} = "";

$conf{rw}{sqluser} = "slurm";
$conf{rw}{sqlpass} = "";
$conf{rw}{sqlnetwork} = "192.168.%.%";

read_config ();

$conf{sqlhost} = "localhost" if ($conf{localhost});

#############################
# Attempt to connect to slurm database
#############################

# test whether slurm db already exists by trying to connect
my $dbh = connect_db_rw ();

# optionally drop existing database
if ($conf{drop}) {
    if ($dbh) {
        log_verbose ("drop: Dropping existing slurm_job_log table\n");
        drop_slurm_joblog_table ();
        $dbh = disconnect_db_rw ();
    }
    else {
        log_verbose ("drop: No existing slurm DB to drop\n");
    }
}

if ($conf{create} && $dbh) {
    log_verbose ("create: SLURM database already exists.\n");
}
elsif ($conf{create} && !$dbh) {
    # the db may not exist (couldn't connect), try to create it
    create_db ();
    # try to connect again
    $dbh = connect_db_rw() 
        or log_fatal ("Failed to connect to SLURM DB after create!\n");
}

# convert slurm_job_log table to version 2 (add procs and extend nodelist columns)
if ($conf{convert}) {
    # attempt to convert table to version 2, if conversion fails, print an error
    # if the table has already been converted, a message is printed and no action is taken
    if (!slurm_job_log_table_convert_to_v2 ()) {
        log_fatal ("convert: SLURM job log table failed conversion.\n");
    }
    return;
}

# optionally backfill from logfiles
if ($conf{backfill}) { 
    if (!$dbh) {
        log_fatal ("Backfill requested, but connection to database failed!\n")
    }
    backfill_from_files($dbh, @ARGV); 
}

if ($conf{info}) {
    show_info ();
}

disconnect_db_rw ();

exit 0;

#############################
# Support functions
#############################

sub connect_db_rw
{
    my $cstr = "DBI:mysql(PrintError=>0):" .
               "database=$conf{db};host=$conf{sqlhost}:";

    my $dbh = DBI->connect($cstr, $conf{rw}{sqluser}, $conf{rw}{sqlpass});

    $conf{dbh}{rw} = $dbh;

    return ($dbh);
}

sub disconnect_db_rw
{
    return if !$conf{dbh}{rw};
    $conf{dbh}{rw}->disconnect;
    return $conf{dbh}{rw} = undef;
}

sub connect_db_root
{
    my $str  = "DBI:mysql(PrintError=>0):;";
    my $host = $conf{use_localhost} ? "localhost" : $conf{sqlhost};

    $str .= "host=$host";

    $conf{dbh}{root} = DBI->connect ($str, "root", $conf{rw}{rootpass}) 
        or log_fatal ("Unable to connect to MySQL DB as root\@$host: ",
                      $DBI::errstr, "\n");

    return ($conf{dbh}{root});
}

sub slurm_job_log_table_exists
{
    my $dbh = connect_db_rw () or return 0;
    $dbh->do ("DESCRIBE $conf{db}.slurm_job_log;") or return 0;
    return 1;
}

sub slurm_job_log_table_convert_to_v2
{
    my $dbh = connect_db_rw () or return 0;

    # first check that the procs column is not already defined
    my $sql = "DESCRIBE $conf{db}.slurm_job_log;";
print "$sql\n";
    my $sth = $dbh->prepare ($sql) or return 0;
    $sth->execute () or return 0;
    while ((my $a = $sth->fetchrow_arrayref)) {
        if ($a->[0] eq "procs") {
            log_msg ("convert: SLURM job log table has already been converted.\n");
            return 1;
        }
    }

    # didn't find procs (would have returned already if we did)

    # extend nodelist column and add procs column
#    $sql = "ALTER TABLE $conf{db}.slurm_job_log CHANGE `nodelist` `nodelist` VARCHAR(4096) NOT NULL, ADD `procs` INT(10) NOT NULL;";
    $sql = "ALTER TABLE $conf{db}.slurm_job_log MODIFY `nodelist` BLOB NULL, ADD `procs` INT(10) NULL AFTER `nodecount`;";
print "$sql\n";
#    $dbh->do ($sql) or return 0;

    # since we changed the schema regarding varchar columns, let MySQL optimize it again (don't know whether this is necessary)
    $sql = "OPTIMIZE TABLE $conf{db}.slurm_job_log;";
print "$sql\n";
#    $dbh->do ($sql) or return 0;

    return 1;
}

sub read_config 
{
    my $ro = "$conf{confdir}/sqlog.conf";
    my $rw = "$conf{confdir}/slurm-joblog.conf";

    # First read sqlog config to get SQLHOST and SQLDB
    #  (ignore SQLUSER/SQLPASS)
    unless (my $rc = do $ro) {
        log_fatal ("Couldn't parse $ro: $@\n") if $@;
        log_fatal ("couldn't run $ro\n") if (defined $rc && !$rc);
    }

    $conf{db}          = $conf::SQLDB   if (defined $conf::SQLDB);
    $conf{sqlhost}     = $conf::SQLHOST if (defined $conf::SQLHOST);
    $conf{ro}{sqluser} = $conf::SQLUSER if (defined $conf::SQLUSER);
    $conf{ro}{sqlpass} = $conf::SQLPASS if (defined $conf::SQLPASS);


    undef $conf::SQLUSER;
    undef $conf::SQLPASS;

    # Now read slurm-joblog.conf
    -r $rw  || log_fatal ("Unable to read required config file: $rw.\n");
    unless (my $rc = do $rw) {
        log_fatal ("Couldn't parse $rw: $@\n") if $@;
        log_fatal ("couldn't run $rw\n") if (defined $rc && !$rc);
    }

    $conf{rw}{sqluser}    = $conf::SQLUSER     if (defined $conf::SQLUSER);
    $conf{rw}{sqlpass}    = $conf::SQLPASS     if (defined $conf::SQLPASS);
    $conf{rw}{rootpass}   = $conf::SQLROOTPASS if (defined $conf::SQLROOTPASS);
    $conf{rw}{sqlnetwork} = $conf::SQLNETWORK  if (defined $conf::SQLNETWORK);

    @{$conf{rw}{hosts}} = @conf::SQLRWHOSTS if (defined @conf::SQLRWHOSTS);

    my %seen;
    @{$conf{rw}{hosts}} = grep {$_ && !$seen{$_}++} @{$conf{rw}{hosts}};

}

# Connect to MySQL as root user to build slurm db and insert slurm and slurm_read users
sub create_db 
{
    my $dbh = connect_db_root () 
        or log_fatal ("Couldn't connect to database as root\n");

    #  
    #  Abort if slurm_job_log table already exists.
    if (slurm_job_log_table_exists ()) {
        log_msg ("create: SLURM job log table exists. No create necessary.\n");
        return;
    }

    #############################
    # Create slurm db / table
    #############################

    log_verbose ("Creating slurm DB\n");
    do_sql ($dbh, "CREATE DATABASE IF NOT EXISTS $conf{db};"); 
    do_sql ($dbh, "USE $conf{db};");             # Switch to use the db

    log_verbose ("Creating new slurm_job_log table\n");
    create_slurm_joblog_table ($dbh);            

    #############################
    # Set up slurm (r/w) and slurm_read (r/o) access 
    #############################

    # Switch to management databases
    do_sql($dbh, "USE mysql;");

    log_verbose ("Dropping previous slurm joblog db users and privileges.\n");
    drop_slurm_users ($dbh);

    # set up permissions for different users of slurm database
    for my $host (@{$conf{rw}{hosts}}, "localhost") {
        my $user = $conf{rw}{sqluser};
        log_verbose ("Granting rw privileges to $user on $host\n");
        do_sql ($dbh, 
                "GRANT ALL ON $conf{db}.* TO" .
                " '$user'\@'$host'" .
                " IDENTIFIED BY '$conf{rw}{sqlpass}'"); 
    }

    log_verbose ("Granting readonly privs to $conf{ro}{sqluser} " .
                 "on $conf{rw}{sqlnetwork}.\n");
    do_sql ($dbh, 
            "GRANT SELECT ON $conf{db}.* TO" .
            " $conf{ro}{sqluser}\@'$conf{rw}{sqlnetwork}'" .
            " IDENTIFIED BY ''");

    # flush privileges to make our changes current
    log_verbose ("FLUSH PRIVILEGES\n");
    do_sql($dbh, "FLUSH PRIVILEGES;");

    # we're done
    log_verbose ("Done creating slurm joblog DB.\n");
}

sub show_info 
{
    my $dbh = connect_db_rw () or return;
    my $stmt = "SELECT COUNT(*) FROM slurm.slurm_job_log;";
    
    my $sth = $dbh->prepare ($stmt) or return;

    $sth->execute () or return;

    my ($count) = $sth->fetchrow_array;

    log_msg ("Information for SLURM job log DB:\n");
    print "DB Host:   $conf{sqlhost}\n";
    print "DB User:   $conf{ro}{sqluser}\n";
    print "RW User:   $conf{rw}{sqluser}\n";
    print "SLURM DB:  $conf{db}\n";
    print "Job count: $count\n";
    
    return;
}

sub drop_slurm_users
{
    my $dbh = shift @_;
    my $stmt = "SELECT user,host from mysql.user;";
    my @oldusers = ();

    my $sth = $dbh->prepare ($stmt) or return;
    $sth->execute () or return;

    while ((my $a = $sth->fetchrow_arrayref)) {
        if ($a->[0] ne "$conf{ro}{sqluser}"  &&
            $a->[0] ne "$conf{rw}{sqluser}" ) {
                next;
        }
        push (@oldusers, "$a->[0]\@'$a->[1]'");
    }
    do_sql ($dbh, "DROP USER " . join (", ", @oldusers)) if @oldusers;
}

# given a dbh and list of slurm job completion logfiles, insert them into the dbh
sub backfill_from_files 
{
    my $dbh = shift @_;
    my @files = @_;

    log_error ("No files to backfill!\n") if (!@files);

    foreach my $file (@files) {
        my @values = ();
        my $count = 0;
        my $skipped = 0;

        my $f = $file;
        $f = "gzip -dc $f | " if ($f =~ /\.gz$/);

        open (IN, $f) or log_error ("Failed to open \"$file\":$!\n"), next;

        while (my $line = <IN>) {
            chomp $line;
            my @parts = split(" ", $line);

            my %hash = ();
            foreach my $part (@parts) {
                my ($key, $value) = split("=", $part);
                $hash{$key} = $value;
            }

            # Some very old joblog files may have the incorrect
            #  datetime format. Unfortunately, the year wasn't 
            #  included in these, so we have to drop these entries :-(
            if ($hash{StartTime} =~ m{^\d\d/\d\d-}) {
                $skipped++;
                next;
            }

            # convert from slurm log to format for MySQL
            my $userid = $hash{"UserId"};
            my ($username, $usernumb) = ($userid =~ /(.+)\((\d+)\)/);
            $hash{"UserName"} = $username;
            $hash{"UserNumb"} = $usernumb;
            $hash{"StartTime"} =~ s/T/ /;
            $hash{"EndTime"} =~ s/T/ /;

            push @values, value_string(\%hash);
            
            if (@values > 100) {
                insert_values($dbh, @values);
                @values = ();
            }
            $count++;
        }
        insert_values($dbh, @values);

        log_verbose ("Backfilled $count jobs from file $file\n");
        log_error ("Skipped $skipped job(s) from file $file because of ",
                  "old date format\n") if $skipped;

        close(IN);
    }
}

# execute (do) sql statement on dbh
sub do_sql {
    my ($dbh, $stmt) = @_;
    log_debug ("SQL: $stmt\n");
    log_error ("SQL: $stmt failed.\n") unless $dbh->do ($stmt);
}

sub drop_slurm_joblog_table 
{
    my $dbh = shift @_ || connect_db_root ();
    do_sql ($dbh, "USE $conf{db};"); 
    do_sql ($dbh, "DROP TABLE slurm_job_log;");
}

# drop and rebuild the table
sub create_slurm_joblog_table {
    my $dbh = shift @_ || connect_db_root ();

    do_sql ($dbh, "USE $conf{db};"); 

    # nodelist can be null since some jobs are canceled before ever being assigned resources
    # procs can be null since this data was not captured in the first version of the table;
    # we don't want 0's in fields which should have non-zero values (jobs that actually ran)
    my $sql = "CREATE TABLE slurm_job_log (
        id        int(10)   NOT NULL AUTO_INCREMENT,
        jobid     int(10)   NOT NULL,
        username  char(100) NOT NULL,
        userid    int(10)   NOT NULL,
        jobname   char(100) NOT NULL,
        jobstate  char(25)  NOT NULL,
        partition char(25)  NOT NULL,
        timelimit int(10)   NOT NULL,
        starttime datetime  NOT NULL,
        endtime   datetime  NOT NULL,
        nodelist  blob          NULL,
        nodecount int(10)   NOT NULL,
        procs     int(10)       NULL,
        PRIMARY KEY (id),
        UNIQUE INDEX jobid (jobid,starttime),
        INDEX username (username)
       ) TYPE=MyISAM;";
    do_sql ($dbh, $sql);
}

# given hash of values, create mysql values string for insert statement
sub value_string {
  my $h = shift @_;
  my @parts = ();

  push @parts, "NULL";
  push @parts, $dbh->quote($h->{JobId});
  push @parts, $dbh->quote($h->{UserName});
  push @parts, $dbh->quote($h->{UserNumb});
  push @parts, $dbh->quote($h->{Name});
  push @parts, $dbh->quote($h->{JobState});
  push @parts, $dbh->quote($h->{Partition});
  push @parts, $dbh->quote($h->{TimeLimit});
  push @parts, $dbh->quote($h->{StartTime});
  push @parts, $dbh->quote($h->{EndTime});
  push @parts, $dbh->quote($h->{NodeList});
  push @parts, $dbh->quote($h->{NodeCnt});

  return "(" . join(',', @parts) . ")";
}

# do a batch insert to be more efficient
sub insert_values 
{
    my $dbh = shift @_;
    my @values = @_;

    while (@values) {
        my @subvalues = ();
        for (my $i = 0; $i < 50 and @values; $i++) { 
            push @subvalues, shift @values; 
        }
        my $sql = "INSERT IGNORE INTO slurm_job_log VALUES " . 
            join(",", @subvalues) . ";";

        #log_debug ("SQL: $sql\n");
        $dbh->do($sql);
    }
}

#
#  Generate a digest of the password, sha1 or md5 depending on the
#   size of the password column in the user table
#
sub passwd_digest
{
    my $dbh = connect_db_root ();
    my $passwd = shift @_;

    log_fatal ("passwd_digest: Failed to get DB handle!\n") if !$dbh;

    my $sth = $dbh->prepare ("SELECT PASSWORD('example');") 
        or log_fatal ($dbh->errstr);

    $sth->execute ();

    my ($r) = $sth->fetchrow_array ();

    if (length $r >= 41) {
        return "*" . sha1_hex ($passwd);
    } 

    #  I don't know what the short password hash is, so 
    #   use of this function is disabled for now.
    #
    #return (unpack ("H16", pack ("A13", $c)));
}

sub log_msg     { print STDERR "$progname: ", @_;       }
sub log_error   { log_msg ("Error: ", @_);              }
sub log_fatal   { log_msg ("Fatal: ", @_); exit 1;      }
sub log_verbose { log_msg (@_) if ($conf{verbose});     }
sub log_debug   { log_msg (@_) if ($conf{verbose} > 1); }

# vi: ts=4 sw=4 expandtab
